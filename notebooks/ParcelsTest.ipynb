{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matt's parcels tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports modules and renames them short names\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from matplotlib import pyplot as plt, animation\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from IPython.display import HTML\n",
    "from salishsea_tools import nc_tools, places\n",
    "\n",
    "# imports functions? from the parcels module\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, AdvectionRK4, AdvectionRK4_3D\n",
    "\n",
    "# makes the plots show up below the code cells\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the default font size of matplotlib plots\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fieldset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldset_from_nemo(daterange, coords):\n",
    "    \"\"\"Generate a fieldset from a hourly SalishSeaCast forcing fields\n",
    "    over daterange.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequential list of forcing file prefixes\n",
    "    prefixes = [\n",
    "        nc_tools.get_hindcast_prefix(daterange[0] + timedelta(days=d)) # This uses the get_hindcast_prefix function which I think is from SalishSeaTools and was made by the MOAD group. It sets the prefix with results/salishsea... etc. so you dont have to specify that\n",
    "        for d in range(np.diff(daterange)[0].days + 1)\n",
    "    ]\n",
    "\n",
    "    # Predefine fieldset argument dictionaries\n",
    "    filenames, variables, dimensions = {}, {}, {}\n",
    "\n",
    "    # Define dict fields for each variable\n",
    "    for var, name in zip(['U', 'V', 'W'], ['vozocrtx', 'vomecrty', 'vovecrtz']):\n",
    "\n",
    "        # Dict of filenames containing the coordinate and forcing variables\n",
    "        datafiles = [prefix + f'_grid_{var}.nc' for prefix in prefixes]\n",
    "        filenames[var] = {'lon': coords, 'lat': coords, 'data': datafiles}\n",
    "\n",
    "        # NEMO variable name\n",
    "        variables[var] = name\n",
    "\n",
    "        # Dict of NEMO coordinate names (f-points)\n",
    "        dimensions[var] = {'lon': 'glamf', 'lat': 'gphif', 'time': 'time_counter'}\n",
    "        \n",
    "        # Add depth fields (f-points are on W grid)\n",
    "        filenames[var]['depth'] = prefixes[0] + '_grid_W.nc'\n",
    "        dimensions[var]['depth'] = 'depthw'\n",
    "\n",
    "    # Load NEMO forcing into fieldset\n",
    "    field_set = FieldSet.from_nemo(filenames, variables, dimensions, field_chunksize='auto')\n",
    "    \n",
    "    return field_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteParticle(particle, fieldset, time):\n",
    "    print(f'Particle {particle.id} lost !! [{particle.lon}, {particle.lat}, {particle.depth}, {particle.time}]')\n",
    "    particle.delete()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and filenames\n",
    "paths = {\n",
    "    'coords': '/data/SalishSeaCast/grid/coordinates_seagrid_SalishSea201702.nc',\n",
    "    'mask': '/data/SalishSeaCast/grid/mesh_mask201702.nc',\n",
    "    'results': '/ocean/mattmiller/MOAD/analysis-matt/results/parcels/test',\n",
    "}\n",
    "\n",
    "# Load coords and mask files and extract grid variables\n",
    "coords, mask = [xr.open_dataset(paths[key], decode_times=False) for key in ('coords', 'mask')]\n",
    "gridlon, gridlat = [coords[key][0, ...].values for key in ('glamt', 'gphit')]\n",
    "tmask = mask.tmask[0, 0, ...].values\n",
    "\n",
    "# Define release parameters\n",
    "location = 'Strait of Georgia'\n",
    "n = 100   # number of particles\n",
    "r = 50   # radius of particle cloud [m]\n",
    "\n",
    "# Start time, duration and timestep\n",
    "start = datetime(2019, 1, 1, 12, 30, 0)\n",
    "duration = timedelta(days=3)\n",
    "dt = timedelta(seconds=90)\n",
    "\n",
    "# Create Gaussian distribution around release point\n",
    "mean, cov = [0, 0], [[r**2, 0], [0, r**2]]\n",
    "x_offset, y_offset = np.random.multivariate_normal(mean, cov, n).T\n",
    "lon, lat = places.PLACES[location]['lon lat']\n",
    "lons = lon + x_offset / 111000 / np.cos(np.deg2rad(lat))\n",
    "lats = lat + y_offset / 111000\n",
    "\n",
    "# Forcing daterange (I add 1-day buffers)\n",
    "daterange = [start - timedelta(days=1), start + duration + timedelta(days=1)]\n",
    "\n",
    "# Output file prefix\n",
    "strings = [location] + [t.strftime('%Y%m%dT%H%M%S') for t in (start, start + duration)]\n",
    "prefix = os.path.join(paths['results'], '_'.join(strings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particle simulations (3D)\n",
    "\n",
    "Build forcing fieldset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File /data/SalishSeaCast/grid/coordinates_seagrid_SalishSea201702.nc could not be decoded properly by xarray (version 2023.1.0).\n",
      "         It will be opened with no decoding. Filling values might be wrongly parsed.\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "Field received an unexpected keyword argument \"field_chunksize\" (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3442\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[8], line 2\u001b[0m\n    fieldset = fieldset_from_nemo(daterange, paths['coords'])\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[4], line 33\u001b[0m in \u001b[1;35mfieldset_from_nemo\u001b[0m\n    field_set = FieldSet.from_nemo(filenames, variables, dimensions, field_chunksize='auto')\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/parcels/fieldset.py:494\u001b[0m in \u001b[1;35mfrom_nemo\u001b[0m\n    fieldset = cls.from_c_grid_dataset(filenames, variables, dimensions, mesh=mesh, indices=indices, time_periodic=time_periodic,\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/parcels/fieldset.py:609\u001b[0m in \u001b[1;35mfrom_c_grid_dataset\u001b[0m\n    return cls.from_netcdf(filenames, variables, dimensions, mesh=mesh, indices=indices, time_periodic=time_periodic,\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/parcels/fieldset.py:416\u001b[0m in \u001b[1;35mfrom_netcdf\u001b[0m\n    fields[var] = Field.from_netcdf(paths, (var, name), dims, inds, grid=grid, mesh=mesh, timestamps=timestamps,\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/parcels/field.py:476\u001b[0m in \u001b[1;35mfrom_netcdf\u001b[0m\n    return cls(variable, data, grid=grid, timestamps=timestamps,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/conda_envs/analysis-matt/lib/python3.10/site-packages/parcels/field.py:215\u001b[0;36m in \u001b[0;35m__init__\u001b[0;36m\n\u001b[0;31m    raise SyntaxError('Field received an unexpected keyword argument \"%s\"' % list(kwargs.keys())[0])\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Field received an unexpected keyword argument \"field_chunksize\"\n"
     ]
    }
   ],
   "source": [
    "# Load SalishSeaCast results into fieldset\n",
    "fieldset = fieldset_from_nemo(daterange, paths['coords'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-matt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0820408f94f9adab353dd622003a8ca360cea5172f3643d18b5213ac85f01b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
